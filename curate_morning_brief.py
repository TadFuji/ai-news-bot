"""
curate_morning_brief.py â€” Stage 2: æœåˆŠã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

Stage 1 (03:00 JST) ã§åé›†ãƒ»1æ¬¡ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã‚ŒãŸå€™è£œè¨˜äº‹ã‚’èª­ã¿è¾¼ã¿ã€
Gemini 2æ¬¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã€Œç·¨é›†çš„ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

å‡ºåŠ›: output/morning_brief_YYYYMMDD.json
"""

import os
import json
import glob
import datetime
from google import genai
from dotenv import load_dotenv
from config import NEWS_BOT_OUTPUT_DIR

load_dotenv()


def load_candidates():
    """æœ¬æ—¥ã®å€™è£œJSONã‚’ã™ã¹ã¦èª­ã¿è¾¼ã¿ã€è¨˜äº‹ã‚’çµ±åˆãƒ»é‡è¤‡æ’é™¤ã™ã‚‹"""
    JST = datetime.timezone(datetime.timedelta(hours=9))
    today_str = datetime.datetime.now(JST).strftime("%Y%m%d")

    # candidates_YYYYMMDD_*.json ã¨ ai_news_YYYYMMDD_*.json ã®ä¸¡æ–¹ã‚’èª­ã‚€
    patterns = [
        os.path.join(NEWS_BOT_OUTPUT_DIR, f"candidates_{today_str}_*.json"),
        os.path.join(NEWS_BOT_OUTPUT_DIR, f"ai_news_{today_str}_*.json"),
    ]

    all_articles = []
    files_loaded = 0

    for pattern in patterns:
        for filepath in glob.glob(pattern):
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    data = json.load(f)

                articles = data.get("articles", []) if isinstance(data, dict) else data
                all_articles.extend(articles)
                files_loaded += 1
                print(f"  ğŸ“„ Loaded: {os.path.basename(filepath)} ({len(articles)} articles)")
            except Exception as e:
                print(f"  âš ï¸ Skip {filepath}: {e}")

    # URLé‡è¤‡æ’é™¤ï¼ˆç›´è¿‘ã®ã‚‚ã®ã‚’å„ªå…ˆï¼‰
    seen_urls = set()
    unique = []
    for a in reversed(all_articles):  # æ–°ã—ã„ã‚‚ã®ã‚’å„ªå…ˆ
        url = a.get("url", "")
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique.append(a)

    unique.reverse()  # å…ƒã®é †åºã«æˆ»ã™

    print(f"\nğŸ“Š å€™è£œçµ±åˆ: {files_loaded} files â†’ {len(all_articles)} articles â†’ {len(unique)} unique")
    return unique


def get_delivered_urls(days=3):
    """éå»Næ—¥é–“ã® morning_brief_*.json ã‹ã‚‰é…ä¿¡æ¸ˆã¿URLã‚’å–å¾—"""
    delivered = set()
    JST = datetime.timezone(datetime.timedelta(hours=9))
    today = datetime.datetime.now(JST)

    for i in range(1, days + 1):
        past_date = (today - datetime.timedelta(days=i)).strftime("%Y%m%d")
        filepath = os.path.join(NEWS_BOT_OUTPUT_DIR, f"morning_brief_{past_date}.json")

        if os.path.exists(filepath):
            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    data = json.load(f)
                for article in data.get("articles", []):
                    url = article.get("url", "")
                    if url:
                        delivered.add(url)
                print(f"  ğŸ“‹ æ—¢é…ä¿¡: {os.path.basename(filepath)} ({len(data.get('articles', []))} articles)")
            except Exception as e:
                print(f"  âš ï¸ Skip {filepath}: {e}")

    print(f"  ğŸ”’ éå»{days}æ—¥é–“ã®é…ä¿¡æ¸ˆã¿URL: {len(delivered)} ä»¶")
    return delivered


def curate_with_gemini(candidates):
    """Gemini 2æ¬¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç·¨é›†çš„ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return None

    client = genai.Client(api_key=api_key)

    # å€™è£œè¨˜äº‹ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    articles_text = ""
    for i, a in enumerate(candidates[:20], 1):
        title = a.get("title_ja", a.get("title", "No Title"))
        summary = a.get("summary_ja", a.get("summary", ""))
        category = a.get("category", "æœªåˆ†é¡")
        score = a.get("importance_score", 0)
        source = a.get("source", "Unknown")
        url = a.get("url", "")

        articles_text += f"""
---
å€™è£œ{i}:
ã‚¿ã‚¤ãƒˆãƒ«: {title}
1æ¬¡ã‚¹ã‚³ã‚¢: {score}/10
ã‚«ãƒ†ã‚´ãƒª: {category}
ã‚½ãƒ¼ã‚¹: {source}
è¦ç´„: {summary[:500]}
URL: {url}
"""

    prompt = f"""# Role Definition
ã‚ãªãŸã¯ã€ŒAntigravity Morning Briefã€ã®ç·¨é›†é•·ã§ã™ã€‚
1æ¬¡é¸åˆ¥æ¸ˆã¿ã®AIãƒ‹ãƒ¥ãƒ¼ã‚¹å€™è£œã‹ã‚‰ã€ä»Šæœã®èª­è€…ã«å±Šã‘ã‚‹æœ€çµ‚ç‰ˆã‚’ç·¨é›†ã—ã¦ãã ã•ã„ã€‚

# Mission
å˜ãªã‚‹ã‚¹ã‚³ã‚¢é †ã®ä¸¦ã¹æ›¿ãˆã§ã¯ãªãã€**ä»Šæ—¥ã®AIæ¥­ç•Œã®ç©ºæ°—æ„Ÿã‚’ä¼ãˆã‚‹ã€ŒæœåˆŠ1é¢ã€** ã‚’ä½œã‚‹ã“ã¨ãŒç›®çš„ã§ã™ã€‚

# Instructions

## Step 1: ãƒ†ãƒ¼ãƒç™ºè¦‹
å€™è£œè¨˜äº‹ã‚’ä¿¯ç°ã—ã€ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«é€šåº•ã™ã‚‹ã€Œãƒ†ãƒ¼ãƒã€ã‚’1ã¤ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
ä¾‹: ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®æ°‘ä¸»åŒ–ãŒåŠ é€Ÿã—ã¦ã„ã‚‹ã€ã€Œæ—¥æœ¬ä¼æ¥­ã®AIæŠ•è³‡ãŒæœ¬æ ¼åŒ–ã€ãªã©ã€‚

## Step 2: è¨˜äº‹é¸å®šï¼ˆå¿…ãš10ä»¶ï¼‰
ä»¥ä¸‹ã®åŸºæº–ã§ **å¿…ãš10ä»¶** ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚å€™è£œãŒ10ä»¶ä»¥ä¸Šã‚ã‚‹å ´åˆã¯å³é¸ã—ã€10ä»¶æœªæº€ã®å ´åˆã¯å€™è£œã®å…¨ä»¶ã‚’æ¡ç”¨ã—ã¦ãã ã•ã„ã€‚
**é‡è¦: articlesã®é…åˆ—ã«ã¯å¿…ãš10ä»¶ï¼ˆå€™è£œãŒ10ä»¶æœªæº€ãªã‚‰å…¨ä»¶ï¼‰ã‚’å«ã‚ã¦ãã ã•ã„ã€‚5ä»¶ã‚„7ä»¶ã§ã¯ä¸ååˆ†ã§ã™ã€‚**
- ãƒ†ãƒ¼ãƒã¨ã®é–¢é€£æ€§ï¼ˆã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®ä¸€è²«æ€§ï¼‰
- èª­è€…ã®ã€Œæ˜æ—¥ã®è¡Œå‹•ã€ã‚’å¤‰ãˆã‚‹åŠ›
- ã‚½ãƒ¼ã‚¹ã®å¤šæ§˜æ€§ï¼ˆåŒã˜ãƒ¡ãƒ‡ã‚£ã‚¢ã«åã‚‰ãªã„ï¼‰
- é€Ÿå ±æ€§ï¼ˆæ—¢ã«åºƒãçŸ¥ã‚‰ã‚ŒãŸæƒ…å ±ã¯ä¸‹ä½ã«ï¼‰

## Step 3: å„è¨˜äº‹ã®ä»˜åŠ ä¾¡å€¤ã‚’è¿½åŠ 
å„è¨˜äº‹ã«å¯¾ã—ã¦ä»¥ä¸‹ã‚’æ—¥æœ¬èªã§è¿½è¨˜ã—ã¦ãã ã•ã„ï¼š
- **one_liner**: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ ¸å¿ƒã‚’20æ–‡å­—ä»¥å†…ã§è¡¨ç¾ï¼ˆä¾‹: 'AIè­°äº‹éŒ²ãŒå…¨ç¤¾æ¨™æº–ã¸'ï¼‰
- **why_important**: 40ä»£ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ãŒæ˜æ—¥ã®ä»•äº‹ã§æ„è­˜ã™ã¹ãã“ã¨ï¼ˆ1-2æ–‡ï¼‰
- **action_item**: èª­è€…ãŒä»Šæ—¥ã™ãã§ãã‚‹å…·ä½“çš„ãª1ã¤ã®è¡Œå‹•ï¼ˆä¾‹: 'ç¤¾å†…ã®å®šå‹æ¥­å‹™ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦ã¿ã¦ãã ã•ã„'ï¼‰

## Step 4: ä»Šæœã®ä¸€è¨€
èª­è€…ãŒæœ€åˆã«èª­ã‚€ã€Œç·¨é›†é•·ã‚³ãƒ¡ãƒ³ãƒˆã€ã‚’40æ–‡å­—ä»¥å†…ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
ãƒˆãƒ¼ãƒ³ã¯ã€ä¿¡é ¼æ„Ÿã®ã‚ã‚‹è½ã¡ç€ã„ãŸå£èª¿ã§ã€‚ä¾‹:ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã€ã¤ã„ã«"ä½¿ãˆã‚‹æ®µéš"ã¸ã€

# Output Format (JSON only)
{{
  "theme": "ä»Šæ—¥ã®ãƒ†ãƒ¼ãƒï¼ˆ20æ–‡å­—ä»¥å†…ï¼‰",
  "morning_comment": "ä»Šæœã®ä¸€è¨€ï¼ˆ40æ–‡å­—ä»¥å†…ï¼‰",
  "articles": [
    {{
      "title_ja": "æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«",
      "summary_ja": "æ—¥æœ¬èªè¦ç´„",
      "one_liner": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ ¸å¿ƒã‚’20æ–‡å­—ä»¥å†…ã§ï¼ˆä¾‹: 'AIè­°äº‹éŒ²ãŒå…¨ç¤¾æ¨™æº–ã¸'ï¼‰",
      "why_important": "ãªãœé‡è¦ã‹ï¼ˆ40ä»£ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³å‘ã‘, 1-2æ–‡ï¼‰",
      "action_item": "èª­è€…ãŒä»Šæ—¥ã™ãã§ãã‚‹1ã¤ã®è¡Œå‹•ï¼ˆä¾‹: 'ç¤¾å†…ã®å®šå‹æ¥­å‹™ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦ã¿ã¦ãã ã•ã„'ï¼‰",
      "category": "ã‚«ãƒ†ã‚´ãƒª",
      "importance_score": 1-10,
      "source": "ã‚½ãƒ¼ã‚¹å",
      "url": "URL"
    }}
  ]
}}

---
å€™è£œè¨˜äº‹ãƒªã‚¹ãƒˆ:
{articles_text}
---

é‡è¦: JSON ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãªã©ã¯ä¸è¦ã§ã™ã€‚
"""

    print("ğŸ§  Gemini 2æ¬¡ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
    try:
        response = client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=prompt,
        )
        response_text = response.text.strip()

        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯é™¤å»
        if response_text.startswith("```"):
            lines = response_text.split("\n")
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines[-1].startswith("```"):
                lines = lines[:-1]
            response_text = "\n".join(lines)

        result = json.loads(response_text)
        curated_articles = result.get("articles", [])
        print(f"âœ… 2æ¬¡ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
        print(f"   ãƒ†ãƒ¼ãƒ: {result.get('theme', 'â€”')}")
        print(f"   ä¸€è¨€: {result.get('morning_comment', 'â€”')}")
        print(f"   Gemini é¸å®š: {len(curated_articles)} ä»¶")

        # Gemini ãŒ10ä»¶æœªæº€ã—ã‹è¿”ã•ãªã‹ã£ãŸå ´åˆã€å€™è£œã‹ã‚‰è£œå®Œã™ã‚‹
        if len(curated_articles) < 10 and len(candidates) > len(curated_articles):
            curated_urls = {a.get("url", "") for a in curated_articles}
            remaining = [
                a for a in candidates if a.get("url", "") not in curated_urls
            ]
            # 1æ¬¡ã‚¹ã‚³ã‚¢ã®é«˜ã„é †ã«è£œå®Œ
            remaining.sort(
                key=lambda x: x.get("importance_score", 0), reverse=True
            )
            needed = 10 - len(curated_articles)
            supplement = remaining[:needed]
            if supplement:
                print(f"   ğŸ“Œ Geminié¸å®šãŒ{len(curated_articles)}ä»¶ã®ãŸã‚ã€"
                      f"å€™è£œã‹ã‚‰{len(supplement)}ä»¶ã‚’è£œå®Œ")
                curated_articles.extend(supplement)
            result["articles"] = curated_articles

        print(f"   æœ€çµ‚é¸å®š: {len(result.get('articles', []))} ä»¶")
        return result

    except Exception as e:
        print(f"âŒ Gemini 2æ¬¡ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: 1æ¬¡ã‚¹ã‚³ã‚¢ä¸Šä½10ä»¶ã‚’ãã®ã¾ã¾ä½¿ç”¨
        fallback_articles = sorted(
            candidates, key=lambda x: x.get("importance_score", 0), reverse=True
        )[:10]
        return {
            "theme": "æœ¬æ—¥ã®AIæ³¨ç›®ãƒ‹ãƒ¥ãƒ¼ã‚¹",
            "morning_comment": "æœ¬æ—¥ã®é‡è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠå±Šã‘ã—ã¾ã™",
            "articles": fallback_articles,
        }


def save_morning_brief(brief):
    """Morning Brief ã‚’ JSON ã¨ Markdown ã®ä¸¡å½¢å¼ã§ä¿å­˜"""
    jst = datetime.timezone(datetime.timedelta(hours=9))
    now_jst = datetime.datetime.now(jst)
    today_str = now_jst.strftime("%Y%m%d")
    updated_str = now_jst.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")

    # JSON (distribute_daily.py äº’æ›)
    json_filename = f"morning_brief_{today_str}.json"
    json_filepath = os.path.join(NEWS_BOT_OUTPUT_DIR, json_filename)

    # distribute_daily.py ã® get_latest_report() ãŒ { "articles": [...] } ã‚’æœŸå¾…
    output_data = {
        "theme": brief.get("theme", ""),
        "morning_comment": brief.get("morning_comment", ""),
        "articles": brief.get("articles", []),
    }

    with open(json_filepath, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… JSON ä¿å­˜: {json_filepath}")

    # Markdown
    md_filename = f"morning_brief_{today_str}.md"
    md_filepath = os.path.join(NEWS_BOT_OUTPUT_DIR, md_filename)

    articles = brief.get("articles", [])
    with open(md_filepath, "w", encoding="utf-8") as f:
        f.write(f"# â˜€ï¸ Antigravity Morning Brief\n\n")
        f.write(f"**{updated_str} (JST)**\n\n")
        f.write(f"## ğŸ¯ ä»Šæ—¥ã®ãƒ†ãƒ¼ãƒ: {brief.get('theme', '')}\n\n")
        f.write(f"> {brief.get('morning_comment', '')}\n\n")
        f.write("---\n\n")

        for i, a in enumerate(articles, 1):
            title = a.get("title_ja", "No Title")
            summary = a.get("summary_ja", "")
            one_liner = a.get("one_liner", "")
            why = a.get("why_important", "")
            action = a.get("action_item", "")
            source = a.get("source", "Unknown")
            url = a.get("url", "")
            category = a.get("category", "æœªåˆ†é¡")

            f.write(f"## {i}. {title}\n\n")
            f.write(f"**ã‚«ãƒ†ã‚´ãƒª**: {category}\n\n")
            if one_liner:
                f.write(f"ğŸ’¡ **ä¸€è¨€**: {one_liner}\n\n")
            f.write(f"{summary}\n\n")
            if why:
                f.write(f"ğŸ“Œ **ãªãœé‡è¦ï¼Ÿ** {why}\n\n")
            if action:
                f.write(f"ğŸ‘‰ **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: {action}\n\n")
            f.write(f"- **å‡ºå…¸**: {source}\n")
            f.write(f"- **URL**: {url}\n\n")

    print(f"âœ… Markdown ä¿å­˜: {md_filepath}")

    return json_filepath


def main():
    print("=" * 50)
    print("â˜€ï¸ Morning Brief â€” Stage 2 ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
    print("=" * 50)

    # 1. Stage 1 å€™è£œã‚’èª­ã¿è¾¼ã¿
    print("\nğŸ“¡ Stage 1 å€™è£œã‚’èª­ã¿è¾¼ã¿ä¸­...")
    candidates_stage1 = load_candidates()
    stage1_count = len(candidates_stage1)

    # 2. æ–°é®®ãªRSSåé›†ï¼ˆ03:00ã€œ07:00 JST ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ï¼‰
    #    ç±³è¥¿æµ·å²¸ã®åˆå¾Œ = æ—¥æœ¬ã®æ—©æœ â†’ AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æœ€ã‚‚æ´»ç™ºãªæ™‚é–“å¸¯
    print("\nğŸ“¡ æœ€æ–°RSSåé›†ä¸­ï¼ˆ03:00ä»¥é™ã®æ–°ç€ã‚’ã‚­ãƒ£ãƒƒãƒï¼‰...")
    try:
        import collect_rss_gemini
        collect_rss_gemini.main()
    except Exception as e:
        print(f"  âš ï¸ è¿½åŠ RSSåé›†å¤±æ•—ï¼ˆStage 1 å€™è£œã§ç¶šè¡Œï¼‰: {e}")

    # 3. Stage 1 + æ–°è¦ã‚’çµ±åˆã—ã¦å†èª­ã¿è¾¼ã¿
    print("\nğŸ“¡ å…¨å€™è£œã‚’çµ±åˆä¸­...")
    candidates = load_candidates()

    if not candidates:
        print("âŒ å€™è£œãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    new_count = len(candidates) - stage1_count
    print(f"   Stage 1 ã‹ã‚‰ã®å€™è£œ: {stage1_count} ä»¶")
    print(f"   07:00 è¿½åŠ åé›†åˆ†: {max(0, new_count)} ä»¶")
    print(f"   åˆè¨ˆå€™è£œ: {len(candidates)} ä»¶")

    # 3.5. éå»3æ—¥é–“ã®é…ä¿¡æ¸ˆã¿URLã‚’é™¤å¤–ï¼ˆåŒã˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç¹°ã‚Šè¿”ã—é˜²æ­¢ï¼‰
    print("\nğŸ”’ éå»3æ—¥é–“ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ä¸­...")
    delivered_urls = get_delivered_urls(days=3)
    if delivered_urls:
        before = len(candidates)
        candidates = [a for a in candidates if a.get("url", "") not in delivered_urls]
        removed = before - len(candidates)
        if removed > 0:
            print(f"   âœ‚ï¸ éå»ã«é…ä¿¡æ¸ˆã¿ã® {removed} ä»¶ã‚’é™¤å¤– â†’ æ®‹ã‚Š {len(candidates)} ä»¶")
        else:
            print(f"   âœ… é‡è¤‡ãªã—ï¼ˆå…¨ {len(candidates)} ä»¶ãŒæ–°è¦ï¼‰")

    # 4. Gemini 2æ¬¡ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    print("\nğŸ§  2æ¬¡ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œä¸­...")
    brief = curate_with_gemini(candidates)

    if not brief:
        print("âŒ ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # 5. ä¿å­˜
    print("\nğŸ’¾ Morning Brief ã‚’ä¿å­˜ä¸­...")
    json_path = save_morning_brief(brief)

    # 6. é…ä¿¡ï¼ˆå¤±æ•—ã—ã¦ã‚‚ã‚µã‚¤ãƒˆæ›´æ–°ã¯ç¶™ç¶šï¼‰
    print("\nğŸ“¤ é…ä¿¡é–‹å§‹...")
    try:
        import distribute_daily
        distribute_daily.main()
    except Exception as e:
        print(f"  âš ï¸ é…ä¿¡ã‚¨ãƒ©ãƒ¼ï¼ˆã‚µã‚¤ãƒˆæ›´æ–°ã¯ç¶šè¡Œï¼‰: {e}")

    # 7. ã‚µã‚¤ãƒˆæ›´æ–°ï¼ˆé…ä¿¡ã®æˆå¦ã«é–¢ã‚ã‚‰ãšå®Ÿè¡Œï¼‰
    print("\nğŸŒ GitHub Pages æ›´æ–°ä¸­...")
    try:
        import build_pages
        build_pages.build_pages()
    except Exception as e:
        print(f"  âš ï¸ ã‚µã‚¤ãƒˆæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    print("\n" + "=" * 50)
    print("âœ… Morning Brief é…ä¿¡å®Œäº†ï¼")
    print("=" * 50)


if __name__ == "__main__":
    main()
