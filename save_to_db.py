#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ—ãƒ¬ã‚¤ãƒ–ãƒƒã‚¯ã«å¾“ã„ã€news_articlesã¨news_collection_runsãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜ã™ã‚‹ã€‚
DATABASE_URLãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯SQLiteã‚’ä½¿ç”¨ã™ã‚‹ã€‚
"""

import os
import json
import sqlite3
import datetime
from pathlib import Path

# ===== è¨­å®š =====
PROJECT_ROOT = Path(__file__).parent
DOCS_DIR = PROJECT_ROOT / "docs"
DB_PATH = PROJECT_ROOT / "ai_news.db"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€ãªã‘ã‚Œã°SQLiteã‚’ä½¿ç”¨ï¼‰
DATABASE_URL = os.environ.get("DATABASE_URL", f"sqlite:///{DB_PATH}")

JST = datetime.timezone(datetime.timedelta(hours=9))


def get_db_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—ã™ã‚‹"""
    if DATABASE_URL.startswith("sqlite"):
        # SQLiteã®å ´åˆ
        db_path = DATABASE_URL.replace("sqlite:///", "")
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        return conn, "sqlite"
    else:
        # MySQL/PostgreSQLã®å ´åˆï¼ˆpymysqlã¾ãŸã¯psycopg2ã‚’ä½¿ç”¨ï¼‰
        try:
            import pymysql
            # mysql://user:pass@host:port/dbname
            conn = pymysql.connect(
                host=_parse_url(DATABASE_URL)["host"],
                user=_parse_url(DATABASE_URL)["user"],
                password=_parse_url(DATABASE_URL)["password"],
                database=_parse_url(DATABASE_URL)["database"],
                port=_parse_url(DATABASE_URL).get("port", 3306),
                charset="utf8mb4",
                cursorclass=pymysql.cursors.DictCursor
            )
            return conn, "mysql"
        except ImportError:
            print("pymysqlãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚SQLiteã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
            conn = sqlite3.connect(str(DB_PATH))
            conn.row_factory = sqlite3.Row
            return conn, "sqlite"


def _parse_url(url):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URLã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    from urllib.parse import urlparse
    parsed = urlparse(url)
    return {
        "host": parsed.hostname,
        "user": parsed.username,
        "password": parsed.password,
        "database": parsed.path.lstrip("/"),
        "port": parsed.port or 3306
    }


def init_db(conn, db_type):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    cursor = conn.cursor()
    
    if db_type == "sqlite":
        # news_articlesãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                description TEXT,
                category TEXT CHECK(category IN ('policy', 'business', 'technology', 'ethics', 'market')),
                region TEXT CHECK(region IN ('japan', 'usa', 'china', 'india', 'eu')),
                url VARCHAR(1024) UNIQUE,
                source VARCHAR(256),
                publishedAt TIMESTAMP,
                createdAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # news_collection_runsãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_collection_runs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                run_at TIMESTAMP NOT NULL,
                articles_collected INTEGER DEFAULT 0,
                articles_saved INTEGER DEFAULT 0,
                articles_skipped INTEGER DEFAULT 0,
                status TEXT DEFAULT 'success',
                notes TEXT,
                createdAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
    else:
        # MySQL/PostgreSQL
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_articles (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title TEXT NOT NULL,
                description TEXT,
                category ENUM('policy', 'business', 'technology', 'ethics', 'market'),
                region ENUM('japan', 'usa', 'china', 'india', 'eu'),
                url VARCHAR(1024) UNIQUE,
                source VARCHAR(256),
                publishedAt TIMESTAMP NULL,
                createdAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) CHARACTER SET utf8mb4
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_collection_runs (
                id INT AUTO_INCREMENT PRIMARY KEY,
                run_at TIMESTAMP NOT NULL,
                articles_collected INT DEFAULT 0,
                articles_saved INT DEFAULT 0,
                articles_skipped INT DEFAULT 0,
                status VARCHAR(50) DEFAULT 'success',
                notes TEXT,
                createdAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) CHARACTER SET utf8mb4
        """)
    
    conn.commit()
    print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")


def load_today_news():
    """ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹JSONã‚’èª­ã¿è¾¼ã‚€"""
    now_jst = datetime.datetime.now(JST)
    today_str = now_jst.strftime("%Y-%m-%d")
    
    json_path = DOCS_DIR / f"{today_str}.json"
    
    if not json_path.exists():
        # æ˜¨æ—¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç¢ºèª
        yesterday = now_jst - datetime.timedelta(days=1)
        json_path = DOCS_DIR / f"{yesterday.strftime('%Y-%m-%d')}.json"
    
    if not json_path.exists():
        print(f"âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_path}")
        return None
    
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    print(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {json_path}")
    return data


def save_articles(conn, db_type, articles):
    """è¨˜äº‹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹"""
    cursor = conn.cursor()
    saved = 0
    skipped = 0
    
    for article in articles:
        url = article.get("url", "")
        title = article.get("title", "")
        description = article.get("summary", article.get("description", ""))
        category = article.get("category", "technology")
        region = article.get("region", "usa")
        source = article.get("source", "")
        published_at_str = article.get("publishedAt", "")
        
        # ã‚«ãƒ†ã‚´ãƒªã®æ­£è¦åŒ–
        category_map = {
            "æœ€æ–°æŠ€è¡“": "technology",
            "æ¥­å‹™åŠ¹ç‡åŒ–": "business",
            "æ³•è¦åˆ¶ãƒ»å€«ç†": "ethics",
            "æ—¥æœ¬å¸‚å ´": "japan",
            "ãƒªã‚¹ã‚¯ç®¡ç†": "ethics",
            "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«": "business",
        }
        if category in category_map:
            category = category_map[category]
        
        # æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã«æ­£è¦åŒ–
        valid_categories = ["policy", "business", "technology", "ethics", "market"]
        if category not in valid_categories:
            category = "technology"
        
        # æœ‰åŠ¹ãªåœ°åŸŸã«æ­£è¦åŒ–
        valid_regions = ["japan", "usa", "china", "india", "eu"]
        if region not in valid_regions:
            region = "usa"
        
        # å…¬é–‹æ—¥æ™‚ã®ãƒ‘ãƒ¼ã‚¹
        published_at = None
        if published_at_str:
            try:
                published_at = datetime.datetime.fromisoformat(
                    published_at_str.replace("Z", "+00:00")
                )
            except (ValueError, AttributeError):
                published_at = datetime.datetime.now(datetime.timezone.utc)
        
        try:
            if db_type == "sqlite":
                cursor.execute("""
                    INSERT OR IGNORE INTO news_articles 
                    (title, description, category, region, url, source, publishedAt)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    title, description, category, region, url, source,
                    published_at.isoformat() if published_at else None
                ))
                if cursor.rowcount > 0:
                    saved += 1
                    print(f"  âœ… ä¿å­˜: {title[:50]}...")
                else:
                    skipped += 1
                    print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {title[:50]}...")
            else:
                cursor.execute("""
                    INSERT IGNORE INTO news_articles 
                    (title, description, category, region, url, source, publishedAt)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (
                    title, description, category, region, url, source,
                    published_at
                ))
                if cursor.rowcount > 0:
                    saved += 1
                    print(f"  âœ… ä¿å­˜: {title[:50]}...")
                else:
                    skipped += 1
                    print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {title[:50]}...")
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {title[:50]}... - {e}")
            skipped += 1
    
    conn.commit()
    return saved, skipped


def save_collection_run(conn, db_type, run_at, articles_collected, articles_saved, articles_skipped, status="success", notes=""):
    """å®Ÿè¡Œãƒ­ã‚°ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹"""
    cursor = conn.cursor()
    
    if db_type == "sqlite":
        cursor.execute("""
            INSERT INTO news_collection_runs 
            (run_at, articles_collected, articles_saved, articles_skipped, status, notes)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            run_at.isoformat(),
            articles_collected,
            articles_saved,
            articles_skipped,
            status,
            notes
        ))
    else:
        cursor.execute("""
            INSERT INTO news_collection_runs 
            (run_at, articles_collected, articles_saved, articles_skipped, status, notes)
            VALUES (%s, %s, %s, %s, %s, %s)
        """, (
            run_at,
            articles_collected,
            articles_saved,
            articles_skipped,
            status,
            notes
        ))
    
    conn.commit()
    print(f"âœ… å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def main():
    print("=" * 60)
    print("ğŸ—„ï¸  AIãƒ‹ãƒ¥ãƒ¼ã‚¹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 60)
    print(f"DATABASE_URL: {DATABASE_URL[:50]}...")
    
    run_at = datetime.datetime.now(JST)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    print("\nğŸ“¡ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šä¸­...")
    conn, db_type = get_db_connection()
    print(f"âœ… æ¥ç¶šæˆåŠŸ (ã‚¿ã‚¤ãƒ—: {db_type})")
    
    # 2. ãƒ†ãƒ¼ãƒ–ãƒ«åˆæœŸåŒ–
    print("\nğŸ”§ ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
    init_db(conn, db_type)
    
    # 3. ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    data = load_today_news()
    
    if not data:
        save_collection_run(conn, db_type, run_at, 0, 0, 0, "error", "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        conn.close()
        return
    
    articles = data.get("articles", [])
    print(f"   {len(articles)} ä»¶ã®è¨˜äº‹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    # 4. è¨˜äº‹ã‚’ä¿å­˜
    print("\nğŸ’¾ è¨˜äº‹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ä¸­...")
    saved, skipped = save_articles(conn, db_type, articles)
    
    print(f"\nğŸ“Š ä¿å­˜çµæœ:")
    print(f"   ä¿å­˜æˆåŠŸ: {saved} ä»¶")
    print(f"   ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {skipped} ä»¶")
    
    # 5. å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜
    print("\nğŸ“ å®Ÿè¡Œãƒ­ã‚°ã‚’ä¿å­˜ä¸­...")
    save_collection_run(
        conn, db_type, run_at,
        articles_collected=len(articles),
        articles_saved=saved,
        articles_skipped=skipped,
        status="success",
        notes=f"ãƒ†ãƒ¼ãƒ: {data.get('theme', '')}"
    )
    
    conn.close()
    
    print("\n" + "=" * 60)
    print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†ï¼")
    print("=" * 60)
    
    return saved, skipped


if __name__ == "__main__":
    main()
